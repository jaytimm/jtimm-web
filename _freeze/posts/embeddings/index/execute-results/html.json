{
  "hash": "41449c5847cb303e55735c9a1e616bf5",
  "result": {
    "markdown": "---\ntitle: \"global word embeddings in R\"\ndate: \"2022-07-12\"\ncategories: [nlp, lexical semantics]\ndescription: 'A uniform approach'\n\nbibliography: /home/jtimm/pCloudDrive/GitHub/jtimm_web/biblio.bib\nimage: preview.png\n\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    number-sections: true\n---\n\n\n\n![](preview.png){width=100% .preview-image}\n\n> A uniform approach to global word embeddings in R.\n\n\n\n---\n\n\n## Some text data via PubMed\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\npmids <- PubmedMTK::pmtk_search_pubmed(search_term = 'medical marijuana', \n                                       fields = c('TIAB','MH'),\n                                       verbose = F)\n\nabstracts0 <- PubmedMTK::pmtk_get_records2(pmids = pmids$pmid, \n                                          cores = 6, \n                                          ncbi_key = key) |> \n  data.table::rbindlist() |> \n  filter(!is.na(abstract)) |>\n  mutate(abstract = tolower(abstract))\n```\n:::\n\n\n\n## Data structures & parameters\n\n### Tokenization\n\n::: {.cell}\n\n```{.r .cell-code}\ntoks <- abstracts0 |> \n  rename(doc_id = pmid, text = abstract) |>\n  text2df::tif2token()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmwes <- text2df::tok2collocations(toks, remove_stops = T)\ntoks0 <- toks |> text2df::token2mwe(mwes)\n```\n:::\n\n\n### TIF\n\n::: {.cell}\n\n```{.r .cell-code}\nntif <- data.frame(doc_id = abstracts0$pmid,\n                   text = unlist(lapply(toks0, paste0, collapse = ' ')))\n```\n:::\n\n\n\n### Model parameters\n\n::: {.cell}\n\n```{.r .cell-code}\ndims <- 50\nwindow <- 5\nmin_count <- 5\n```\n:::\n\n\n\n## GloVe embeddings\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nit <- text2vec::itoken(toks0, progressbar = FALSE)\nvocab <- text2vec::create_vocabulary(it) |>\n  text2vec::prune_vocabulary(term_count_min = min_count)\n\nvectorizer <- text2vec::vocab_vectorizer(vocab)\ntcm <- text2vec::create_tcm(it, vectorizer, skip_grams_window = window)\n\nglove <- text2vec::GlobalVectors$new(rank = dims, x_max = 10)\nwv_main <- glove$fit_transform(tcm, \n                               n_iter = 10, \n                               convergence_tol = 0.01, \n                               n_threads = 6)\nwv_context <- glove$components\nglove_embeddings <- wv_main + t(wv_context)\n```\n:::\n\n\n\n\n## word2vec/doc2vec embeddings\n\n::: {.cell}\n\n```{.r .cell-code}\n## d2v <- list(dm = 'PV-DM', bow = 'PV-DBOW')\nmodel.d2v <- doc2vec::paragraph2vec(x = ntif, \n                                    type = \"PV-DM\", \n                                    dim = dims, \n                                    iter = 20,\n                                    min_count = min_count, \n                                    lr = 0.05, \n                                    threads = 5)\n\nd2v_embeddings <- as.matrix(model.d2v, which = \"words\")\n```\n:::\n\n\n\n\n## fastText embeddings\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## devtools::install_github(\"pommedeterresautee/fastrtext\") \ntmp_file_txt <- tempfile()\ntmp_file_model <- tempfile()\nwriteLines(text = ntif$text, con = tmp_file_txt)\n\nfastrtext::execute(commands = c(\"skipgram\",\n                                \"-input\", tmp_file_txt, \n                                \"-output\", tmp_file_model, \n                                \"-dim\", gsub('^.*\\\\.', '', dims),\n                                \"-ws\", window, \n                                \"-minCount\", min_count,\n                                \"-verbose\", 1))\n\nfast.model <- fastrtext::load_model(tmp_file_model)\nfast.dict <- fastrtext::get_dictionary(fast.model)\nfast_embeddings <- fastrtext::get_word_vectors(fast.model, fast.dict)\n```\n:::\n\n\n## Pretrained GloVe embeddings\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(locald)\nglove.6B.50d <- data.table::fread('glove.6B.50d.txt')\nglove_pretrained <- as.matrix(glove.6B.50d[, 2:51])\nrownames(glove_pretrained) <- glove.6B.50d$V1\nglove_pretrained <- subset(glove_pretrained, \n                           rownames(glove_pretrained) %in% fast.dict)\n```\n:::\n\n\n\n\n\n\n\n\n## Semantics & cosine similarity \n\n### Collate models\n\n> Note that the pretrained GloVe model does not include multi-word expressions. \n\n::: {.cell}\n\n```{.r .cell-code}\nmodels <- list('glove' = glove_embeddings,\n               'word2vec' = d2v_embeddings,\n               'fastText' = fast_embeddings,\n               'glove_pretrained' = glove_pretrained)\n\nlapply(models, dim)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$glove\n[1] 5690   50\n\n$word2vec\n[1] 5692   50\n\n$fastText\n[1] 5691   50\n\n$glove_pretrained\n[1] 5062   50\n```\n:::\n:::\n\n\n\n### Cosine similarity \n\n::: {.cell}\n\n```{.r .cell-code}\nquick_cosine <- function (embeddings,\n                          target, \n                          n = 9) {\n  \n  if(is.character(target)){\n    t0 <- embeddings[target, , drop = FALSE]} else{t0 <- target}\n\n  cos_sim <- text2vec::sim2(x = embeddings,\n                            y = t0,\n                            method = \"cosine\",\n                            norm = \"l2\")\n\n  x1 <- head(sort(cos_sim[,1], decreasing = TRUE), n+1)\n\n  data.frame(rank = 1:(n+1),\n             term1 = rownames(t0),\n             term2 = names(x1),\n             value = round(x1, 3),\n             row.names = NULL)\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlapply(models, quick_cosine, target = 'legalization') |> #'legality'\n  data.table::rbindlist(idcol = 'model') |>\n  select(-term1, -value) |>\n  tidyr::spread(model, term2) |>\n  knitr::kable()\n```\n\n::: {.cell-output-display}\n| rank|fastText          |glove        |glove_pretrained  |word2vec          |\n|----:|:-----------------|:------------|:-----------------|:-----------------|\n|    1|legalization      |legalization |legalization      |legalization      |\n|    2|decriminalization |marijuana    |legalizing        |legalisation      |\n|    3|pre-legalization  |recreational |legalize          |legalizing        |\n|    4|liberalization    |medical      |decriminalization |passage           |\n|    5|post-legalization |use          |legalisation      |use               |\n|    6|commercialization |cannabis     |legalized         |decriminalization |\n|    7|medicalization    |its          |proponents        |enactment         |\n|    8|legalisation      |state        |advocates         |implementation    |\n|    9|legalizing        |medicinal    |decriminalisation |legalize          |\n|   10|normalization     |before       |abstinence        |laws              |\n:::\n:::\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}